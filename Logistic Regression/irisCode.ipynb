{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "irisCode.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1vp2AZ3ewF4X4W13JKE9XOAXa0TYy-MtI",
      "authorship_tag": "ABX9TyO2bygwNSb2ioC8aEM5vqBH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProtikBose/Machine-Learning-Algorithms/blob/master/Logistic%20Regression/irisCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzNzydH0syFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the tools we need\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Regular EDA (exploratory data analysis) and plotting libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# we want our plots to appear inside the notebook\n",
        "%matplotlib inline \n",
        "\n",
        "# Models from Scikit-Learn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Model Evaluations\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Hx2mL8z0L04",
        "colab_type": "text"
      },
      "source": [
        "**CSV reading**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKrCpj4DtgD3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e6102c82-0ac0-4565-9d8e-37f4b5b2833c"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/Machine Learning Algorithm/Logistic Regression/iris.csv\") \n",
        "df.head()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "      <th>Output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width species  Output\n",
              "0           5.1          3.5           1.4          0.2  setosa       1\n",
              "1           4.9          3.0           1.4          0.2  setosa       1\n",
              "2           4.7          3.2           1.3          0.2  setosa       1\n",
              "3           4.6          3.1           1.5          0.2  setosa       1\n",
              "4           5.0          3.6           1.4          0.2  setosa       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaiNBq5Sus-L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7258362a-9001-40a2-aa90-d5c7763e541a"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species',\n",
              "       'Output'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CiWbGTkzEqE",
        "colab_type": "text"
      },
      "source": [
        "**Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CWcPPib8MZc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ea99219e-c5e0-4d47-d24a-ea39fe37316c"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sepal_length    float64\n",
              "sepal_width     float64\n",
              "petal_length    float64\n",
              "petal_width     float64\n",
              "species          object\n",
              "Output            int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQBJ3Xd5u7pT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "5a0b45ee-79a7-416e-8ed7-5f4f152ae890"
      },
      "source": [
        "# creating instance of labelencoder\n",
        "labelencoder = LabelEncoder()\n",
        "\n",
        "df['species'] = labelencoder.fit_transform(df['species'])\n",
        "df['species'].values"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYo4Ius1zYI9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "68783c87-486c-4019-f4f4-4ee61c97670e"
      },
      "source": [
        "df['sepal_length'] = df['sepal_length']/np.max(df['sepal_length'])\n",
        "df['sepal_width'] = df['sepal_width']/np.max(df['sepal_width'])\n",
        "df['petal_length'] = df['petal_length']/np.max(df['petal_length'])\n",
        "df['petal_width'] = df['petal_width']/np.max(df['petal_width'])\n",
        "df.head()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "      <th>Output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.728571</td>\n",
              "      <td>0.795455</td>\n",
              "      <td>0.274510</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>0.274510</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.671429</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.254902</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.657143</td>\n",
              "      <td>0.704545</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.274510</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width  species  Output\n",
              "0      0.728571     0.795455      0.274510     0.111111        0       1\n",
              "1      0.700000     0.681818      0.274510     0.111111        0       1\n",
              "2      0.671429     0.727273      0.254902     0.111111        0       1\n",
              "3      0.657143     0.704545      0.294118     0.111111        0       1\n",
              "4      0.714286     0.818182      0.274510     0.111111        0       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naQV8aFD0cpF",
        "colab_type": "text"
      },
      "source": [
        "**Train-Test Split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOQAjOuyy0bH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.drop(\"Output\",axis=1)\n",
        "Y = df['Output']\n",
        "\n",
        "# Random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Split into train & test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, # independent variables \n",
        "                                                    Y, # dependent variable\n",
        "                                                    test_size = 0.2) # percentage of data to use for test set\n",
        "                                                    "
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL5c761W0iq2",
        "colab_type": "text"
      },
      "source": [
        "**Model Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm62rZew0h1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define the required Sigmoid function\n",
        "def sigmoid(z):\n",
        "    return 1/(1+np.exp(-z))"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbZWmxE10uIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_implementation_Raw(X_train,Y_train, learning_rate=0.0005, max_iteration=1000):\n",
        "  \n",
        "  \n",
        "  #Adding a column of 1's so that the first element of each input is always 1\n",
        "  #It would be multiplied with theta_0 later\n",
        "  X_train= np.insert(X_train, 0, values=1, axis=1)\n",
        "  no_attributes = X_train.shape[1]\n",
        "  \n",
        "  #Initialize model parameters theta\n",
        "  theta = np.zeros((no_attributes,1))\n",
        "  \n",
        "\n",
        "  #Run number of iterations\n",
        "  for icount in range(max_iteration):\n",
        "    #delta is the quantity that will be added with theta during updating theta\n",
        "    delta = np.zeros((no_attributes,1))\n",
        "    totalLogLikelihood = 0\n",
        "    \n",
        "    #Check each data point\n",
        "    for instance, actualOutput in zip(X_train,Y_train):\n",
        "      \n",
        "      instance=instance.reshape(no_attributes,1)\n",
        "      dotResult = np.dot(theta.T, instance)\n",
        "      predictedValue=sigmoid(dotResult).squeeze()\n",
        "      \n",
        "      #Calculate the derivative value for this data point\n",
        "      derivativeValue = instance*(actualOutput-predictedValue)\n",
        "      \n",
        "      #Calculate the amount to be added with theta\n",
        "      delta += learning_rate*derivativeValue\n",
        "\n",
        "      logLikelihood = actualOutput*np.log(predictedValue)+(1-actualOutput)*np.log(1-predictedValue)\n",
        "      totalLogLikelihood += logLikelihood\n",
        "      \n",
        "    theta = theta + delta\n",
        "    '''\n",
        "    #After each 100 iteration, print the status\n",
        "    if icount%100==0:\n",
        "      print(icount)\n",
        "      print(totalLogLikelihood)\n",
        "      print(theta)\n",
        "    '''\n",
        "  #print(theta.shape)\n",
        "  \n",
        "  return theta"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRr4_AlOmw_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_implementation_Matrix(X_train, Y_train, learning_rate=0.0005, max_iteration=1000):\n",
        "  #Adding a column of 1's so that the first element of each input is always 1\n",
        "  #It would be multiplied with theta_0 later\n",
        "  X_train= np.insert(X_train, 0, values=1, axis=1)\n",
        "  #print(X_train.shape)\n",
        "  no_attributes = X_train.shape[1]\n",
        "  Y_train = Y_train.reshape(-1,1)\n",
        "  #print(Y_train.shape)\n",
        "  \n",
        "  #Initialize model parameters theta\n",
        "  theta = np.zeros((no_attributes,1))\n",
        "  #print(theta.shape)\n",
        "  \n",
        "  #Run number of iterations\n",
        "  for icount in range(max_iteration):\n",
        "    #delta is the quantity that will be added with theta during updating theta\n",
        "    delta = np.zeros((no_attributes,1))\n",
        "    totalLogLikelihood = 0\n",
        "    \n",
        "    dotResult = np.dot(X_train,theta)\n",
        "    #print(\"Dot Result: \",dotResult.shape)\n",
        "    predictedValue = sigmoid(dotResult)\n",
        "    #print(\"predictedValue: \",predictedValue.shape)\n",
        "    diff = Y_train - predictedValue\n",
        "    #print(\"diff: \",diff.shape)\n",
        "    derivativeValue = X_train*diff\n",
        "    #print(\"derivativeValue: \",derivativeValue.shape)\n",
        "    delta = learning_rate*derivativeValue\n",
        "    #print(\"delta: \",delta.shape)\n",
        "    delta = np.sum(delta, axis=0).reshape(no_attributes,-1)\n",
        "    #print(\"delta Updated: \",delta.shape)\n",
        "    logLikelihood = Y_train*np.log(predictedValue) + (1-Y_train)*np.log(1-predictedValue)\n",
        "    #print(\"logLikelihood: \",logLikelihood.shape)\n",
        "    totalLogLikelihood = np.sum(logLikelihood)\n",
        "    theta = theta + delta\n",
        "    '''\n",
        "    #After each 100 iteration, print the status\n",
        "    if icount%100==0:\n",
        "      print(icount)\n",
        "      print(totalLogLikelihood)\n",
        "      print(theta)\n",
        "    '''\n",
        "  #print(theta.shape)\n",
        "  \n",
        "  return theta\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0wprAW3ggA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predictionMatrix(X_test, Y_test, theta):\n",
        "  #Adding a column of 1's so that the first element of each input is always 1\n",
        "  #It would be multiplied with theta_0 later\n",
        "  X_test= np.insert(X_test, 0, values=1, axis=1)\n",
        "  no_attributes = X_test.shape[1]\n",
        "\n",
        "  correctCount = 0\n",
        "  totalCount = 0\n",
        "\n",
        "  Y_test = Y_test.reshape(-1,1)\n",
        "  dotResult = np.dot(X_test,theta)\n",
        "  predictedValue = sigmoid(dotResult)\n",
        "  #print(list(zip(predictedValue, Y_test)))\n",
        "  predictedOutput = (predictedValue >= 0.5).astype(int)\n",
        "  resultMatrix = (Y_test == predictedOutput).astype(int)\n",
        "  correctCount = np.sum(resultMatrix)\n",
        "  totalCount = len(resultMatrix)\n",
        "  print(\"Total Correct Count: \",correctCount,\" Total Wrong Count: \",totalCount-correctCount,\" Accuracy: \",(correctCount*100)/(totalCount))\n",
        "  return correctCount*100/(totalCount)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW3mo8AaVvdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predictionRaw(X_test, Y_test, theta):\n",
        "  #Adding a column of 1's so that the first element of each input is always 1\n",
        "  #It would be multiplied with theta_0 later\n",
        "  X_test= np.insert(X_test, 0, values=1, axis=1)\n",
        "  no_attributes = X_test.shape[1]\n",
        "\n",
        "  correctCount = 0\n",
        "  totalCount = 0\n",
        "\n",
        "  #Check each data point\n",
        "  for instance, actualOutput in zip(X_test,Y_test):\n",
        "    instance=instance.reshape(no_attributes,1)\n",
        "    dotResult = np.dot(theta.T, instance)\n",
        "    #Calculated the probability of belonging to class 1\n",
        "    predictedValue=sigmoid(dotResult).squeeze()\n",
        "    \n",
        "    if predictedValue >= 0.5:\n",
        "        predictedOutput = 1\n",
        "    else:\n",
        "        predictedOutput = 0\n",
        "    #print(predictedValue, actualOutput)\n",
        "    if predictedOutput == actualOutput:\n",
        "        correctCount += 1\n",
        "    totalCount += 1\n",
        "\n",
        "  print(\"Total Correct Count: \",correctCount,\" Total Wrong Count: \",totalCount-correctCount,\" Accuracy: \",(correctCount*100)/(totalCount))\n",
        "  return correctCount*100/(totalCount)\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdUQMRaN1kCo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8d7afee0-16de-4d24-f347-5dcab3dce85a"
      },
      "source": [
        "parameters=fit_implementation_Raw(np.array(X_train),np.array(y_train),.01,1000)\n",
        "accuracy=predictionRaw(np.array(X_test), np.array(y_test), parameters)\n",
        "print(accuracy)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Correct Count:  20  Total Wrong Count:  0  Accuracy:  100.0\n",
            "100.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI3sU3z3udps",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4a5c22ad-b876-4903-e37e-477f5baafd3d"
      },
      "source": [
        "parameters=fit_implementation_Matrix(np.array(X_train),np.array(y_train),.01,1000)\n",
        "accuracy=predictionMatrix(np.array(X_test), np.array(y_test), parameters)\n",
        "print(accuracy)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Correct Count:  20  Total Wrong Count:  0  Accuracy:  100.0\n",
            "100.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}